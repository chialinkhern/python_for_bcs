The homework is the same as the lab. You only have to turn in one or the other.

1. Tuesday's lecture and the assigned reading described three main branches of machine learning. What are they, and what
are the situations in which each are useful?

2. If we were going to put it into one of the categories, what type of machine learning would a t-test fall into?
Explain your answer? If you don't know what a t-test is, its from statistics, feel free to ask.

3. What is over-fitting? How does it relate to the idea of type 1 and type 2 errors from statistics?

4. What is normalization, and how does it affect the data we are using? Why is it useful for supervised and unsupervised
learning?

5. In lab we have been using the k-nearest-neighbor algorithm. Which of the three categories is this algorithm in?
Why does it belong in that category? How does the algorithm work?

6. What are some situations where a k-nearest neighbor algorithm might work well? What are some situations where it
wouldn't work very well?

7. In 'classify.py', what does changing the MIN_MAX_KNN parameter do? How does this effect the way the algorithm
performs on data1.csv? Are there values that "break" the program and cause it to crash? Why?

8. What effect does the TRAINING_PROPORTION parameter have, both in terms of how it changes what the
program does, and also in terms of how well the k-nearest-neighbor algorithm is able to classify the data in data1.csv?

9. Why is the k-nearest-neighbor algorithm's accuracy not always the same? Hint: there is a random component. But what
is being randomized? What one line of code could we add to 'classify.py' to make the results consistent and replicable?
What would we be sacrificing by doing so?

10. Why does the k-nearest-neighbor algorithm perform better on data2.csv than on data1.csv? Explain this in terms of the
details of how the algorithm works, not just in terms of why the data in data2.csv is better.

11. What does the function analyses.compute_feature_correlations() do? What do you learn about the data, and the
performance of the classification algorithm, from the output of this method? Make sure you have VERBOSE=True.

12. If you added 20 random features to data2.csv, but retained the existing features, would that make the
k-nearest-neighbor algorithm perform better, worse, or have no effect? Why?


1. Open classify.py and make sure that the parameter settings are set to the following:
        FILE_NAME = 'data/data3.csv'
        TRAINING_PROPORTION = .75
        NORMALIZE = False
        SVD_DIM = 0
        VERBOSE = True
        WORD_LABELS = True
        PLOT_SVDS = False
        F1 = 0
        F2 = 1
        F_INDEX = 2
        C_INDEX = 1
        SIM = None

        # KNN Parameters
        DISTANCE_METRIC = 'cosine'
        MIN_MAX_KNN = (1, 10)

        # Logistic Regression Parameters
        LEARNING_RATE = 0.1
        NUM_EPOCHS = 1000
        OUTPUT_FILE_NAME = 'log_reg_results.txt'

    In the main function, make sure all the lines are commented out EXCEPT:
        np.set_printoptions(precision=3)
        random.seed(RANDOM_SEED)
        np.random.seed(RANDOM_SEED)

        my_data = dataset.Dataset(FILE_NAME, TRAINING_PROPORTION, NORMALIZE, SVD_DIM, VERBOSE)

        my_logreg = lr.LogisticRegression(my_data, LEARNING_RATE, NUM_EPOCHS, VERBOSE, OUTPUT_FILE_NAME)
        my_logreg.train()
        my_logreg.test()

    Run classify.py and explain the output that you observe. If you cannot understand some of the output, look at the
    code, talk with your group, and ask the professor and/or TA.

2. Now uncomment the K-Nearest Neighbor code and run that at the same time. Compare the performance of two algorithms.
    Which one does better on our dataset? What are specific examples of words that the better model gets right that the
    other model gets wrong? Can you use any of the figures to better justify your answer?

3. Now change the NORMALIZE parameter to True, and re-run the program. Without running the program, hypothesize how
    normalization should affect the KNN and Logistic Regression algorithms. When you have answered that, run the
    program and compare the results to your hypothesis. Was it correct? Why or why not? What do you conclude about the
    effect of normalizing the data?

4. Now change the TRAINING_PROPORTION parameter to 0.20, and re-run the program. Without running the program,
    hypothesize how training proportion should affect the KNN and Logistic Regression algorithms. When you have answered
    that, run the program and compare the results to your hypothesis. Was it correct? Why or why not? What do you
    conclude about the effect of training proportion.

5. In what way would the dataset have to be different to maximize the performance of the KNN algorithm, and most hurt
    the performance of the logistic regression algorithm? Think about how the two are different, and what kinds of data
    are good and bad for each one. Then reverse the question, what kind of data would be best for logistic regression,
    and worst for KNN?
