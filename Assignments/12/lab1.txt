In this lab we are now doing logistic regression. In logistic regression we are still trying to categorize items using
features. But instead of looking at the nearest neighbors as we did in knn, we are taking a different approach.

In logistic regression, we compute a weighted sum of all the features, where the weights are essentially the correlation
of each feature with how predictive it is of a category. So if "proportion of time in air" is positively correlated
with something being a bird, it will have a high positive weight. For any item, we take its features, multiply them all
by the feature weights, and that gives us a score between -inf and +inf telling us how likely the item is in the
category (where 0 means equally likely it is and is not in the category). We then plug the score z into the logistic
function 1/(1+e**-z), converting the number to a value between 0 and 1 that we can interpret as like a probability.

The question is, how do we figure out the weights for each feature. You could try to guess them yourself, but that
would be hard and inefficient. We want an algorithm to do this for us. Their are a number of algorithms we call
"gradient descent error minimizing" algorithms that do this. Here's how they work:
- first, just guess small random values for each feature weight
- use those weights to make predictions about each item in the training set
- for each item, calculate how much 'error' there was for each prediction. In other words, if the guess for lion as a
    mammal was 0.48, and the right answer was 1.00, then the error was -0.52 (i.e. the guess was -0.52 too low).
- use the error to adjust each weight in the "right direction". What is the right direction? Here's the intuition.
    For example, if the "prop time spent on land" for lion was 0.9, and the right answer for lion was 1.0,
    then intuitively we can see that, for this item at least, the feature looks correlated with the category, so we want
    the weight to be positive. After seeing lion with a value of 0.9 on some feature where its correct answer is 1,
    nudge the weight in the positive direction. We dont want to crank it up really high because maybe this item is
    unrepresentative. Now do another feature, "time spent in water", 0.10 for lion. This one is uncorrelated, so we
    want to nudge the weight in a downward direction. By following this procedure iteratively over all the items and
    features many times, we will converge on predictive weights for each feature (usually...).

Let's try.

0. Open classify.py and make sure that the parameter settings are set to the following:
        FILE_NAME = 'data/data1.csv'
        TRAINING_PROPORTION = .75
        NORMALIZE = False
        SVD_DIM = 0
        VERBOSE = True
        WORD_LABELS = True
        PLOT_SVDS = False
        F1 = 0
        F2 = 1
        F_INDEX = 2
        C_INDEX = 1
        SIM = None

        # KNN Parameters
        DISTANCE_METRIC = 'cosine'
        MIN_MAX_KNN = (1, 10)

        # Logistic Regression Parameters
        LEARNING_RATE = 0.1
        NUM_EPOCHS = 1000
        OUTPUT_FILE_NAME = 'log_reg_results.txt'

        GENERATE_PLOTS = False

    In the main function:
        - comment out the 4 knn model lines (59-62)
        - uncomment the 4 logreg model lines (64-67)

    Run classify.py. You will see a bunch of "epochs" printed out (usually pronouned eeepock). That is the model
    taking one pass through each item in the training set, and adjusting its weights a little for each one. It
    prints out the SSE (sum squared error), the sum of the square of how different each item's guess is from what it
    should be. There are 64 items in the dataset, and so if each item's starting guess was about 0.50 (which it tends to
    be because all the weights are random at the beginning and cancel out), then the error for each item will be about
    1.00 - 0.50 = 0.50, squared = 0.25, summed = 0.25*64 = 16. These models usually start a little worse than that, it
    will have a starting error of about 22. At the end of 1000 epochs, it will have an accuracy score of maybe around
    80-90%%. This is determined by taking its guess for each word for each category (the output number between 0 and 1)
    and treating it as a guess of "yes" if the value was above 0.5, and no if it was below 0.5.

1. Which words did it perform poorly on. Why does it makes sense that it did so?

2. Now change GENERATE_PLOTS to True. There are two new plots (after the first three, which you can comment out if you
    want):
    - the first new one plots the weights the model learned between each feature and each category
    - the second plots its predictive value for a category on the x-axis, and the right answer (0 or 1) on the x axis.
        note you can change C_INDEX to change what category you are plotting.
    What are three things you notice about the items and categories and classification looking at these plots?

3. Now change to dataset data3.csv, and redo and reanswer questions 1 and 2. Make sure you say how it does different
    from dataset data1.csv, and why.

4. Focus on the difference between the accuracy on the training set and the test set. Why are they different from each
other? Explain what the difference is between the training and test set, and why the scores come out different. Then
repeat the manipulation of training proportion of lab0. How does this affect the training and test accuracy. Why does it
make sense that it changes the way that it does? What is meant by the term overfitting, and how does it explain what
happens here when the size of the training set is too small?

5. What is the difference between the logreg and knn algorithms?
    - Explain the difference qualitatively, in terms of how they work. What are circumstances where they would perform
        differently, and where one or the other might lead to better classification?
    - Explain the difference quantitatively. Which one has higher accuracy on all three datasets, data1, data2, and
    data3?? Run each model 100 times, and calculate the mean and stdev accuracy of all 6 of these models (the knn run
    on all three datasets, and the logreg on all three). Don't do this manually. Write code! Plot this data using a 2x3
    bar chart, with the stdev as error bars.



